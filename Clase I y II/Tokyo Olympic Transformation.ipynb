{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d01f2e9-f0e2-47f2-a695-aa628fc77fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Carga de Datos desde Volúmenes en Databricks\n",
    "\n",
    "## ¿Qué son los Volúmenes en Databricks?\n",
    "\n",
    "Los **volúmenes** en Databricks son una funcionalidad de Unity Catalog que proporciona almacenamiento unificado y gobernado para archivos no estructurados. En este ejemplo, utilizamos un volumen para cargar múltiples archivos CSV de datos olímpicos.\n",
    "\n",
    "### Estructura de la Ruta del Volumen\n",
    "\n",
    "La ruta `/Volumes/workspace/dbtest/dataclase2/` sigue la estructura estándar de volúmenes:\n",
    "\n",
    "- **`/Volumes/`**: Prefijo que indica el uso del sistema de volúmenes\n",
    "- **`workspace`**: Nombre del catálogo (catalog)\n",
    "- **`dbtest`**: Nombre del esquema (schema) \n",
    "- **`dataclase2`**: Nombre del volumen específico\n",
    "\n",
    "### Dataset Olímpico\n",
    "\n",
    "Trabajaremos con un conjunto de datos relacionados con los Juegos Olímpicos que incluye:\n",
    "\n",
    "- **`Athletes.csv`**: Información de los atletas participantes\n",
    "- **`Coaches.csv`**: Datos de los entrenadores\n",
    "- **`EntriesGender.csv`**: Distribución por género de las participaciones\n",
    "- **`Medals.csv`**: Registro de medallas otorgadas\n",
    "- **`Teams.csv`**: Información de los equipos nacionales\n",
    "\n",
    "### Ventajas de usar Volúmenes para este caso:\n",
    "\n",
    "- **Organización**: Todos los archivos relacionados en una ubicación centralizada\n",
    "- **Gobernanza**: Control de acceso unificado para todo el dataset\n",
    "- **Rendimiento**: Lectura optimizada de múltiples archivos CSV\n",
    "- **Colaboración**: Acceso compartido y seguro entre equipos\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código demuestra cómo cargar estos archivos CSV desde el volumen utilizando Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "140cd5e8-992c-4cb3-a0c4-53223a4f12ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "LLAMADO DE ARCHIVOS"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la ruta base del volumen\n",
    "base_path = \"/Volumes/workspace/dbtest/dataclase2/\"\n",
    "\n",
    "# Leemos los archivos CSV como DataFrames\n",
    "athletes_df = spark.read.option(\"header\", True).option(\"delimiter\", \",\").csv(f\"{base_path}Athletes.csv\")\n",
    "coaches_df = spark.read.option(\"header\", True).option(\"delimiter\", \",\").csv(f\"{base_path}Coaches.csv\")\n",
    "entries_gender_df = spark.read.option(\"header\", True).option(\"delimiter\", \",\").csv(f\"{base_path}EntriesGender.csv\")\n",
    "medals_df = spark.read.option(\"header\", True).option(\"delimiter\", \",\").csv(f\"{base_path}Medals.csv\")\n",
    "teams_df = spark.read.option(\"header\", True).option(\"delimiter\", \",\").csv(f\"{base_path}Teams.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a593a962-50bb-4e17-a2ab-ddcaa7819613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exploración de DataFrames de Spark\n",
    "\n",
    "## Verificación del Esquema y Contenido\n",
    "\n",
    "Una vez cargados los archivos CSV como DataFrames de Spark, es fundamental realizar una exploración inicial para entender la estructura y el contenido de los datos. Para esto utilizamos dos métodos esenciales:\n",
    "\n",
    "### `printSchema()` - Análisis de la Estructura\n",
    "\n",
    "El método **`printSchema()`** nos permite visualizar la estructura completa del DataFrame, mostrando:\n",
    "\n",
    "- **Nombres de las columnas**: Identificación de cada campo disponible\n",
    "- **Tipos de datos**: String, Integer, Double, Boolean, etc.\n",
    "- **Nullabilidad**: Si la columna permite valores nulos o no\n",
    "- **Jerarquía**: Estructura en forma de árbol que facilita la lectura\n",
    "\n",
    "Esta información es crucial para:\n",
    "- Validar que la carga de datos fue correcta\n",
    "- Identificar posibles problemas de tipos de datos\n",
    "- Planificar transformaciones futuras\n",
    "- Entender la calidad de los datos cargados\n",
    "\n",
    "### `show()` - Previsualización del Contenido\n",
    "\n",
    "El método **`show(n)`** muestra las primeras **n** filas del DataFrame de manera tabular:\n",
    "\n",
    "- **Muestreo rápido**: Vista de los datos reales contenidos\n",
    "- **Validación de contenido**: Verificación de que los datos son consistentes\n",
    "- **Detección de patrones**: Identificación de formatos, valores nulos, etc.\n",
    "- **Control de calidad**: Revisión inicial antes del procesamiento\n",
    "\n",
    "En nuestro caso, `show(5)` muestra las primeras 5 filas de cada DataFrame, proporcionando una muestra representativa sin sobrecargar la salida.\n",
    "\n",
    "### Estrategia de Exploración\n",
    "\n",
    "Para el dataset olímpico, examinaremos únicamente el DataFrame de **atletas** (`athletes_df`) como muestra inicial, manteniendo comentados los demás para evitar una salida excesiva. Esta aproximación nos permite:\n",
    "\n",
    "- Entender la estructura general del dataset\n",
    "- Validar la correcta carga de datos\n",
    "- Identificar patrones antes de procesar todos los DataFrames\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código ejecuta la exploración del esquema y muestra una preview del DataFrame de atletas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6e90e0a-cbce-4afb-8baf-857b3f47554d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SCHEMA Y SHOW"
    }
   },
   "outputs": [],
   "source": [
    "# mostramos el esquema de cada DataFrame\n",
    "# athletes_df.printSchema()\n",
    "coaches_df.printSchema()\n",
    "# entries_gender_df.printSchema()\n",
    "# medals_df.printSchema()\n",
    "# teams_df.printSchema()\n",
    "\n",
    "# Mostramos un preview de cada DataFrame\n",
    "# athletes_df.show(5)\n",
    "# coaches_df.show(5)\n",
    "# entries_gender_df.show(5)\n",
    "medals_df.show(5)\n",
    "# teams_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "055b3c67-9c67-4207-b64c-8d3bc21019bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformación de Tipos de Datos en Spark\n",
    "\n",
    "## Conversión de Columnas Numéricas\n",
    "\n",
    "Después de cargar los datos CSV, es común encontrar que las columnas numéricas se interpreten como tipo `String` por defecto. Para realizar operaciones matemáticas y análisis estadístico, necesitamos convertir estas columnas a sus tipos de datos apropiados.\n",
    "\n",
    "### Importación de Funciones de PySpark\n",
    "\n",
    "Importamos las herramientas necesarias para la transformación:\n",
    "\n",
    "- **`functions as F`**: Módulo que contiene funciones de columna para transformaciones\n",
    "- **`IntegerType`**: Tipo de dato específico para números enteros\n",
    "- **`F.col()`**: Función que referencia una columna existente del DataFrame\n",
    "\n",
    "### Método `withColumn()` - Transformación de Columnas\n",
    "\n",
    "El método **`withColumn()`** permite:\n",
    "\n",
    "- **Modificar columnas existentes**: Cambiar el tipo de dato manteniendo el mismo nombre\n",
    "- **Crear nuevas columnas**: Agregar columnas calculadas al DataFrame\n",
    "- **Transformaciones en cadena**: Aplicar múltiples transformaciones de forma secuencial\n",
    "\n",
    "### Conversión con `cast()`\n",
    "\n",
    "La función **`cast()`** realiza la conversión de tipos de datos:\n",
    "\n",
    "- **Conversión segura**: Maneja automáticamente valores que no pueden convertirse\n",
    "- **Validación implícita**: Los valores no numéricos se convierten en `null`\n",
    "- **Optimización**: Mejora el rendimiento para operaciones matemáticas posteriores\n",
    "\n",
    "### DataFrame Target: `entries_gender_df`\n",
    "\n",
    "Para el DataFrame de distribución por género, convertimos las columnas numéricas:\n",
    "\n",
    "- **`Female`**: Número de participantes femeninas (String → Integer)\n",
    "- **`Male`**: Número de participantes masculinos (String → Integer) \n",
    "- **`Total`**: Total de participantes (String → Integer)\n",
    "\n",
    "Esta transformación es esencial para poder realizar:\n",
    "- Cálculos estadísticos\n",
    "- Agregaciones numéricas\n",
    "- Visualizaciones de datos\n",
    "- Análisis comparativo entre géneros\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código aplica la transformación de tipos de datos y verifica el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f86a74cb-1bc3-439b-b7f3-594fb6ee48a7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CASTEO DE COLUMNAS"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos funciones de PySpark\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convertimos las columnas a IntegerType usando F.col\n",
    "entries_gender_df = entries_gender_df \\\n",
    "    .withColumn(\"Female\", F.col(\"Female\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Male\", F.col(\"Male\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Total\", F.col(\"Total\").cast(IntegerType()))\n",
    "\n",
    "# Mostramos un preview para verificar\n",
    "entries_gender_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b83c1b-f99c-46da-ba2e-5971f86c66f1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "VALIDAR CASTEO"
    }
   },
   "outputs": [],
   "source": [
    "entries_gender_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ca667d-ad13-40e6-b52a-18eb18af940f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Análisis y Ranking de Datos en Spark\n",
    "\n",
    "## Creación de Rankings con Ordenamiento y Selección\n",
    "\n",
    "Una de las tareas más comunes en análisis de datos deportivos es identificar los países con mejor desempeño. En este caso, crearemos un ranking de países basado en el número de medallas de oro obtenidas.\n",
    "\n",
    "### Método `orderBy()` - Ordenamiento de Datos\n",
    "\n",
    "La función **`orderBy()`** permite organizar las filas del DataFrame según criterios específicos:\n",
    "\n",
    "- **Ordenamiento ascendente**: Por defecto, ordena de menor a mayor\n",
    "- **Ordenamiento descendente**: Usando `.desc()` ordena de mayor a menor\n",
    "- **Múltiples columnas**: Permite ordenar por varias columnas simultáneamente\n",
    "- **Referencia de columnas**: Utiliza `F.col(\"nombre_columna\")` para referenciar columnas\n",
    "\n",
    "En nuestro caso, `F.col(\"Gold\").desc()` ordena por medallas de oro de mayor a menor, colocando a los países con más medallas al inicio.\n",
    "\n",
    "### Método `select()` - Selección de Columnas\n",
    "\n",
    "La función **`select()`** permite especificar qué columnas queremos mantener en el resultado:\n",
    "\n",
    "- **Reducción de datos**: Elimina columnas innecesarias para el análisis específico\n",
    "- **Optimización de rendimiento**: Procesa solo los datos requeridos\n",
    "- **Claridad en resultados**: Presenta únicamente la información relevante\n",
    "- **Preparación para visualización**: Estructura los datos para reportes o gráficos\n",
    "\n",
    "Seleccionamos:\n",
    "- **`TeamCountry`**: Nombre del país/equipo\n",
    "- **`Gold`**: Cantidad de medallas de oro obtenidas\n",
    "\n",
    "### Encadenamiento de Operaciones\n",
    "\n",
    "PySpark permite **encadenar métodos** usando el operador `\\` para mejorar la legibilidad:\n",
    "\n",
    "- **Flujo secuencial**: Las operaciones se aplican una tras otra\n",
    "- **Código limpio**: Evita variables temporales innecesarias\n",
    "- **Legibilidad**: Cada operación en una línea separada\n",
    "- **Mantenibilidad**: Fácil de modificar o extender\n",
    "\n",
    "### Objetivo del Análisis\n",
    "\n",
    "Esta consulta nos permite identificar:\n",
    "\n",
    "- **Top performers**: Países con mayor éxito en medallas de oro\n",
    "- **Distribución del rendimiento**: Cómo se distribuye el éxito entre países\n",
    "- **Análisis comparativo**: Diferencias entre el desempeño de diferentes naciones\n",
    "- **Base para visualizaciones**: Datos preparados para gráficos de ranking\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código crea el ranking de países por medallas de oro y muestra los 10 primeros resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1dbbc4d-457b-4db2-aa1e-65047ccc9247",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "RANKING"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Ordenamos por la columna \"Gold\" de manera descendente y seleccionamos país y medallas de oro\n",
    "top_gold_medal_countries = medals_df \\\n",
    "    .orderBy(F.col(\"Gold\").desc()) \\\n",
    "    .select(F.col(\"TeamCountry\"), F.col(\"Gold\"))\n",
    "\n",
    "# Mostramos los primeros resultados\n",
    "top_gold_medal_countries.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "709c7838-b85b-418b-abc1-611a9898e99c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creación de Columnas Calculadas en Spark\n",
    "\n",
    "## Análisis de Proporciones y Promedios por Género\n",
    "\n",
    "Para entender mejor la distribución de género en las diferentes disciplinas olímpicas, calculamos las proporciones relativas de participación femenina y masculina. Esto nos permite realizar comparaciones equitativas independientemente del tamaño total de cada disciplina.\n",
    "\n",
    "### Importación de Funciones\n",
    "\n",
    "Reutilizamos el módulo **`functions as F`** que ya importamos anteriormente, aprovechando sus capacidades para:\n",
    "\n",
    "- **Operaciones matemáticas**: Realizar cálculos entre columnas\n",
    "- **Referencia de columnas**: Usar `F.col()` para operaciones aritméticas\n",
    "- **Transformaciones**: Crear nuevas columnas basadas en datos existentes\n",
    "\n",
    "### Método `withColumn()` para Cálculos\n",
    "\n",
    "Utilizamos **`withColumn()`** para crear columnas calculadas que representen proporciones:\n",
    "\n",
    "- **Cálculos en tiempo real**: Las operaciones se realizan durante la ejecución\n",
    "- **Preservación de datos**: Mantiene todas las columnas originales\n",
    "- **Múltiples transformaciones**: Permite encadenar varios cálculos\n",
    "\n",
    "### Operaciones Aritméticas entre Columnas\n",
    "\n",
    "Las operaciones matemáticas en Spark se realizan usando `F.col()`:\n",
    "\n",
    "- **División**: `F.col('Female') / F.col('Total')` calcula la proporción femenina\n",
    "- **Precisión decimal**: Automáticamente maneja la precisión de los cálculos\n",
    "- **Manejo de nulos**: Gestiona valores nulos de manera segura\n",
    "- **Optimización**: Las operaciones se distribuyen eficientemente\n",
    "\n",
    "### Columnas Calculadas Específicas\n",
    "\n",
    "Creamos dos nuevas columnas de proporción:\n",
    "\n",
    "- **`Avg_Female`**: Proporción de participantes femeninas (Female/Total)\n",
    "  - Valor entre 0 y 1, donde 1 = 100% participación femenina\n",
    "- **`Avg_Male`**: Proporción de participantes masculinos (Male/Total)\n",
    "  - Valor entre 0 y 1, donde 1 = 100% participación masculina\n",
    "\n",
    "### Valor Analítico\n",
    "\n",
    "Este análisis proporcional nos permite:\n",
    "\n",
    "- **Comparaciones equitativas**: Evaluar representación de género independientemente del tamaño\n",
    "- **Identificación de patrones**: Detectar disciplinas con mayor/menor equilibrio de género\n",
    "- **Análisis de diversidad**: Medir la inclusión en diferentes deportes olímpicos\n",
    "- **Base para métricas**: Calcular estadísticas de paridad de género\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código calcula las proporciones de género por disciplina y muestra los primeros 10 resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "227067b1-3b5b-4a01-a3d1-5bf3f5972cd7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "COLUMNAS CALCULADAS"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculamos el promedio de entradas por género para cada disciplina\n",
    "average_entries_by_gender = entries_gender_df \\\n",
    "    .withColumn('Avg_Female', F.col('Female') / F.col('Total')) \\\n",
    "    .withColumn('Avg_Male', F.col('Male') / F.col('Total'))\n",
    "\n",
    "# Mostramos los resultados\n",
    "average_entries_by_gender.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03904d1f-8497-44a2-8491-ed46589a3320",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "¿Cómo verificar qué países tienen más de 10 medallas de oro?"
    }
   },
   "outputs": [],
   "source": [
    "medals_df.display()\n",
    "\n",
    "medals_df = medals_df.withColumn(\"Gold\", F.col(\"Gold\").cast(\"int\"))\n",
    "\n",
    "medals_df.display()\n",
    "\n",
    "df_oro = (\n",
    "    medals_df\n",
    "    .filter(F.col(\"Gold\") > 10)\n",
    "    .select(F.col(\"TeamCountry\"), F.col(\"Gold\"))\n",
    "    .orderBy(F.col(\"Gold\").desc())\n",
    ")\n",
    "df_oro.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1201695797254400,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Tokyo Olympic Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
