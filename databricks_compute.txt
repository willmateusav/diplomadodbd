游댳 Componentes principales de Databricks (explicaci칩n breve)

1. Workspace
   - Es el entorno colaborativo donde los equipos trabajan.
   - Contiene notebooks, dashboards, repositorios y librer칤as.
   - Ejemplo: un cient칤fico de datos crea un notebook para entrenar un modelo y otro miembro del equipo puede revisarlo en el mismo workspace.

2. Repos / Data
   - Repos: integraci칩n con GitHub, GitLab o Azure DevOps para versionamiento de c칩digo.
   - Data: donde se gestionan cat치logos, esquemas y tablas (unificaci칩n de datos bajo el modelo Lakehouse).

3. Compute
   - Donde se crean y configuran los cl칰steres o entornos de ejecuci칩n (con Spark debajo).
   - Permite correr notebooks, jobs o cargas ETL.

4. Jobs
   - Permite programar tareas y pipelines (por ejemplo: correr una ETL diaria que transforma datos en Delta Lake).

5. ML & AI
   - M칩dulos para experimentaci칩n, entrenamiento y despliegue de modelos de Machine Learning.
   - Ejemplo: un equipo entrena un modelo de predicci칩n de churn y lo despliega en producci칩n.

------------------------------------------------------------

游댳 Compute en detalle

El compute es b치sicamente el motor de ejecuci칩n dentro de Databricks (los cl칰steres o entornos que procesan los datos).

Caracter칤sticas principales:
1. Tipos de cl칰steres
   - Interactive Clusters: usados por analistas o cient칤ficos de datos en notebooks.
   - Job Clusters: creados autom치ticamente para correr un job programado y luego se apagan.
   - SQL Warehouses: especializados en consultas SQL interactivas o BI.

2. Configuraci칩n flexible
   - Puedes elegir tama침o y tipo de nodos (workers, drivers).
   - Puedes definir escalado autom치tico (autoscaling) para ajustar el n칰mero de nodos seg칰n la carga de trabajo.
   - Integraci칩n con instancias de AWS, Azure o GCP (seg칰n la nube que uses).

3. Optimizaci칩n y control
   - Tags para cost management.
   - Pol칤ticas de cl칰ster para limitar configuraciones.
   - Runtime preconfigurados (con Spark, MLlib, TensorFlow, etc.).

------------------------------------------------------------

游댳 Costos asociados al compute

1. Se cobra por uso
   - Los costos dependen del tiempo que el cl칰ster est치 corriendo y de las instancias que seleccionaste.

2. Factores que influyen en el costo
   - Tipo de instancia (CPU vs GPU, memoria).
   - N칰mero de workers.
   - Tiempo en ejecuci칩n.
   - Uso de funcionalidades premium (ejemplo: serverless).

3. Estrategias de ahorro
   - Autoscaling.
   - Jobs clusters (se prenden y apagan autom치ticamente).
   - Configuraci칩n de tiempo de inactividad para apagado autom치tico.

------------------------------------------------------------

游댳 Diferencia: Compute creado vs. Serverless

Aspecto | Compute creado (cl칰ster manual) | Serverless compute
--------|---------------------------------|--------------------
Gesti칩n | T칰 defines tipo de nodos, tama침o, autoscaling, pol칤ticas. | Databricks gestiona todo (infraestructura invisible para el usuario).
Flexibilidad | Alta: eliges instancias, GPUs, librer칤as, runtime. | Menor: orientado a SQL y consultas r치pidas.
Costos | Pagas por los recursos que configures, incluso si el cl칰ster est치 ocioso. | Pagas por segundo de ejecuci칩n de la query.
Casos de uso | Workloads pesados, ETLs, ML, pipelines complejos. | Consultas SQL interactivas, dashboards BI, anal칤tica ad-hoc.
Ejemplo | Un data engineer crea un cl칰ster de Spark para procesar logs diarios. | Un analista ejecuta queries en SQL Warehouse sin configurar nodos.

------------------------------------------------------------

游녤 En resumen:
- Si necesitas control y potencia, usas un cl칰ster de compute creado manualmente.
- Si necesitas simplicidad y rapidez para queries SQL, usas serverless compute (SQL Warehouse serverless).
